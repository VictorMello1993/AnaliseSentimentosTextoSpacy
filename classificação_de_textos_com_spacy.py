# -*- coding: utf-8 -*-
"""Classificação de textos com spaCy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Du4H8ktXlqY2NXSrz6TeZAaGbxQc3Xuo

## Etapa 1: Importação e instalação das bibliotecas
"""

!pip install spacy --upgrade

!python3 -m spacy download pt

import pandas as pd
import string
import spacy
import random
import seaborn as sns
import numpy as np

spacy.__version__

"""## Etapa 2: Carregamento da base de dados"""

base_dados = pd.read_csv('/content/BaseTreinamento.txt', encoding='utf-8')

base_dados.shape

base_dados.head()

base_dados.tail()

sns.countplot(base_dados['emocao'], label='Contagem');

"""## Etapa 3: Função para pré-processamento dos textos"""

pontuacoes = string.punctuation
pontuacoes

from spacy.lang.pt.stop_words import STOP_WORDS
stop_words = STOP_WORDS

print(stop_words) #Lista padrão de stopwords em português do SpaCy

len(stop_words)

pln = spacy.load('pt')

pln

def preprocessamento(texto):
  texto = texto.lower()
  documento = pln(texto)
  lista = []
  for token in documento:
    # lista.append(token.text) #Tokenização
    lista.append(token.lemma_) #Lematização

  #Removendo stopwords e pontuações
  lista = [palavra for palavra in lista if palavra not in stop_words and palavra not in pontuacoes]

  #Convertendo uma lista de strings em uma única string após realizar mais processamento como remover dígitos no meio da frase
  lista = ' '.join([elemento for elemento in lista if not elemento.isdigit()]) 

  return lista

teste = preprocessamento('Estou aprendendo 1 10 23 processamento de linguagem natural, curso em Curitiba')
teste

"""## Etapa 4: Pré-processamento da base de dados

###Limpeza dos dados
"""

base_dados.head(10)

#Aplicando pré-processamento dos textos da base de dados
base_dados['texto'] = base_dados['texto'].apply(preprocessamento)

base_dados.head(10)

"""### Tratamento da classe"""

exemplo_base_dados = [['este trabalho é agradável', {'ALEGRIA':True, 'MEDO':False}],
                      ['este lugar continua assustador', {'ALEGRIA':False, 'MEDO':True}]]

type(exemplo_base_dados)

exemplo_base_dados[0]

exemplo_base_dados[0][0]

exemplo_base_dados[0][1]

type(exemplo_base_dados[0][1])

base_dados_final = []
for texto, emocao in zip(base_dados['texto'], base_dados['emocao']):
  if emocao == 'alegria':
    dic = {"ALEGRIA":True, "MEDO":False}
  elif emocao == 'medo':
    dic = {"ALEGRIA":False, "MEDO":True}
  base_dados_final.append([texto, dic.copy()])

base_dados_final

len(base_dados_final)

base_dados_final[0]

base_dados_final[1]

type(base_dados_final[0])

type(base_dados_final[0][0])

type(base_dados_final[0][1])

"""## Etapa 5: Criação do classificador

A biblioteca SpaCy possui um recurso de treinamento que utiliza redes neurais para detecção de padrões dos dados em textos
"""

modelo = spacy.blank('pt') #Inicializando o modelo em branco - Será o nosso classificador
categorias = modelo.create_pipe('textcat') #Criando a categorização de textos
categorias.add_label('ALEGRIA')
categorias.add_label('MEDO')
modelo.add_pipe(categorias)
historico = [] #Lista que irá armazenar os erros obtidos no treinamento

#Treinamento do modelo
modelo.begin_training()
for epoca in range(1000): #Treinamento em 1000 épocas
  random.shuffle(base_dados_final) 
  losses = {}  
  for batch in spacy.util.minibatch(base_dados_final, 30): #batch size de 30: de 30 em 30 registros serão atualizados os pesos  
    textos = [modelo(texto) for texto, entities in batch]
    annotations = [{'cats': entities} for texto, entities in batch]
    modelo.update(textos, annotations, losses=losses) #Atualização dos pesos
  if epoca % 100 == 0:
    print(losses) #Obtendo os erros de 100 em 100 épocas
    historico.append(losses)

historico_loss = []
for i in historico:
  historico_loss.append(i.get('textcat'))

historico_loss = np.array(historico_loss) #Convertendo list para numpy para posteriormente ser utilizado na geração de gráficos
historico_loss

#Plotando gráfico épocas x erros
import matplotlib.pyplot as plt 
plt.plot(historico_loss)
plt.title('Progressão do erro')
plt.xlabel('Épocas')
plt.ylabel('Erro')

"""O gráfico vai nos ajudar a determinar quantas épocas são necessárias para treinamento do modelo. Veja que quando chega a uma determinada época, o erro está muito próximo de zero (no caso entre época 200 e 300, o que significa que não precisa treinar para tantas épocas.

Também é importante levar em consideração que, quando tiver uma base de dados muito grande, poderá levar até horas para concluir o treinamento para o número maior de épocas.
"""

modelo.to_disk('modelo')

"""##Etapa 6: Testes com uma frase"""

#Passo 1: carregar o modelo treinado
modelo_carregado = spacy.load('modelo')
modelo_carregado

texto_positivo = 'eu adoro cor dos seus olhos'

#Passo 2: realizar pré-processamento de um novo texto
texto_positivo = preprocessamento(texto_positivo)
texto_positivo

#Passo 3: submeter o texto tratado ao modelo para efetivamente efetuar classificação
previsao = modelo_carregado(texto_positivo)
previsao

#Passo 4: observar as probabilidades calculadas para cada classe.
previsao.cats

texto_negativo = 'estou com medo dele'
previsao = modelo_carregado(preprocessamento(texto_negativo))
previsao.cats

"""##Etapa 7: Avaliação do modelo

###Avaliação na base de treinamento
"""

previsoes = []
for texto in base_dados['texto']:
  previsao = modelo_carregado(texto) #Submetendo cada texto pré-processado na base de treinamento ao modelo salvo
  previsoes.append(previsao.cats) #Adicionando a classe prevista de cada registro a um array de classes

previsoes

previsoes_final = []
for previsao in previsoes:
  if previsao['ALEGRIA'] > previsao['MEDO']:
    previsoes_final.append('alegria')
  else:
    previsoes_final.append('medo')
previsoes_final = np.array(previsoes_final)

previsoes_final

respostas_reais = base_dados['emocao'].values
respostas_reais

from sklearn.metrics import confusion_matrix, accuracy_score
accuracy_score(respostas_reais, previsoes_final) #Obtendo percentual de acerto

"""Veja que na base de treinamento, a acurácia chegou em 100%. Isso por 2 motivos:
* Foi descoberta uma nova base de dados ou uma técnica nova;
* Houve overfitting (o mais provável), ou seja, o modelo se adaptou demais à mesma base de dados, e assim, na base de testes, provavelmente o resultado será abaixo do esperado.
"""

cm = confusion_matrix(respostas_reais, previsoes_final) #Obtendo a matriz de confusão
cm

"""### Avaliação na base de teste"""

base_dados_teste = pd.read_csv('/content/BaseTeste.txt', encoding='utf-8')

base_dados_teste.head()

base_dados_teste['texto'] = base_dados_teste['texto'].apply(preprocessamento) #Efetuando o pré-processamento da base de testes

base_dados_teste

previsoes = []
for texto in base_dados_teste['texto']:
  previsao = modelo_carregado(texto) #Submetendo cada texto pré-processado na base de testes ao modelo salvo
  previsoes.append(previsao.cats) #Adicionando a classe prevista de cada registro a um array de classes

previsoes_final = []
for previsao in previsoes:
  if previsao['ALEGRIA'] > previsao['MEDO']:
    previsoes_final.append('alegria')
  else:
    previsoes_final.append('medo')
previsoes_final = np.array(previsoes_final)

respostas_reais = base_dados_teste['emocao'].values
respostas_reais

accuracy_score(respostas_reais, previsoes_final) #Obtendo percentual de acerto da base de testes

cm = confusion_matrix(respostas_reais, previsoes_final)
cm