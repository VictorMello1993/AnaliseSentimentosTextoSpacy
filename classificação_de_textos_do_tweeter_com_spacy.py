# -*- coding: utf-8 -*-
"""Classificação de textos do Tweeter com spaCy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13V1-PMQ5hZqqDsdQpZHZ8Mu5EReV9hfv

## Etapa 1: Importação e instalação das bibliotecas
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install spacy --upgrade

import spacy
spacy.__version__

!python3 -m spacy download pt

import pandas as pd
import string
import spacy
import random
import seaborn as sns
import numpy as np
import re

"""## Etapa 2: Carregamento das bases de dados

* Link da Kaggle: https://www.kaggle.com/augustop/portuguese-tweets-for-sentiment-analysis#TweetsNeutralHash.csv

###Base de treinamento
* Negative label: 0
* Positive label: 1
"""

base_treinamento = pd.read_csv('/content/Train50.csv', delimiter=';')

base_treinamento.shape

base_treinamento.head()

base_treinamento.tail()

sns.countplot(base_treinamento['sentiment'], label = 'Contagem');

base_treinamento.drop(['id', 'tweet_date', 'query_used'], axis = 1, inplace=True) #Eliminando colunas irrelevantes do dataframe

base_treinamento.head()

#Verificando se existem registros com valor null em um tweet ou em um sentimento através do mapa de calor
sns.heatmap(pd.isnull(base_treinamento));

"""###Base de testes"""

base_teste = pd.read_csv('/content/Test.csv', delimiter=';', encoding='utf-8')

base_teste.head()

base_teste.tail()

base_teste.drop(['id', 'tweet_date', 'query_used'], axis=1, inplace=True) #Eliminando colunas irrelevantes do dataframe

base_teste.shape

sns.countplot(base_teste['sentiment'], label='Contagem');

base_teste.head()

base_teste.tail()

#Verificando se existem registros com valor null em um tweet ou em um sentimento através do mapa de calor
sns.heatmap(pd.isnull(base_teste));

"""##Etapa 3: Função para pré-processamento de dados

* Letras minúsculas
* Nome do usuário (@)
* URLS
* Espaços em branco
* Emoticons
* Stopwords
* Lematização
* Pontuações
"""

pln = spacy.load('pt')
pln

base_treinamento['tweet_text'][0] #Carregando um tweet

stop_words = spacy.lang.pt.stop_words.STOP_WORDS #Lista de stopwords
print(stop_words)

string.punctuation #Lista de pontuações

def preprocessamento(texto):
  #Letras minúsculas
  texto = texto.lower()

  #Eliminando o nome do usuário usando regex
  texto = re.sub(r'@[A-Za-z0-9$-_@.&+]+', ' ', texto)

  #Eliminando links usando regex
  texto = re.sub(r'https?://[A-Za-z0-9./]+', ' ', texto)

  #Eliminando espaços em branco
  # texto = re.sub(r' +', ' ',texto)
  texto = texto.strip()

  #Eliminando emoticons
  lista_emocoes = {':)': 'emocaopositiva', 
                   ':d': 'emocaopositiva', 
                   ':(': 'emocaonegativa'}

  for emocao in lista_emocoes:
    texto = texto.replace(emocao, lista_emocoes[emocao])

  #Lematização
  documento = pln(texto)
  lista = [token.lemma_ for token in documento]

  #Eliminação de stopwords e pontuações
  lista = [palavra for palavra in lista if palavra not in stop_words and palavra not in string.punctuation]

  #Convertendo todo o array em uma string única
  lista = ' '.join([elemento for elemento in lista if not elemento.isdigit()]) 
  return lista

texto_teste = '@behin_d_curtain Para mim, Ã© precisamente o contrÃ¡rio :) Vem a chuva e vem a boa disposiÃ§Ã£o :)'
resultado = preprocessamento(texto_teste)
resultado

"""##Etapa 4: Pré-processamento da base de dados

###Limpeza dos textos
"""

base_treinamento['tweet_text'] = base_treinamento['tweet_text'].apply(preprocessamento)

base_treinamento.head(10)

base_treinamento.tail(10)

base_teste['tweet_text'] = base_teste['tweet_text'].apply(preprocessamento)

base_teste.head(10)

base_teste.tail(10)

"""###Tratamento da classe"""

exemplo_base_dados = [['este trabalho é agradável', {'ALEGRIA':True, 'MEDO':False}],
                      ['este lugar continua assustador', {'ALEGRIA':False, 'MEDO':True}]]

type(exemplo_base_dados)

exemplo_base_dados[0]

exemplo_base_dados[0][0] #Frase

exemplo_base_dados[0][1] #Emoção

type(exemplo_base_dados[0][1])

type(base_treinamento['sentiment'])

base_dados_treinamento_final = []
for texto, emocao in zip(base_treinamento['tweet_text'], base_treinamento['sentiment']):
  if emocao == 1:
    dic = {'POSITIVA': True, "NEGATIVA":False}
  elif emocao == 0:
    dic = {'POSITIVA': False, "NEGATIVA":True}
  base_dados_treinamento_final.append([texto, dic.copy()])

base_dados_treinamento_final

len(base_dados_treinamento_final)

base_dados_treinamento_final[45000:45005]

base_dados_treinamento_final[0][0] #Frase

base_dados_treinamento_final[0][1] #Emoção

"""##Etapa 5: Criação do classificador"""

modelo = spacy.blank('pt')
categorias = modelo.create_pipe('textcat')
categorias.add_label('POSITIVA')
categorias.add_label('NEGATIVA')
modelo.add_pipe(categorias)
historico = [] #Lista que irá armazenar os erros obtidos no treinamento

import time
import timeit
inicio = timeit.default_timer()
modelo.begin_training()
for epoca in range(20): #Executando em 20 épocas
  random.shuffle(base_dados_treinamento_final) #Deixando os registros no formato aleatório
  losses = {}  
  for batch in spacy.util.minibatch(base_dados_treinamento_final, 512): #Em cada batch serão atualizados os pesos de 512 em 512 registros
    textos = [modelo(texto) for texto, entities in batch]
    annotations = [{'cats': entities} for texto, entities in batch] #Categorias de emoções (classes)
    modelo.update(textos, annotations, losses=losses) #Atualização dos pesos
    historico.append(losses)
  if epoca % 5 == 0: #Mostrando os erros a cada 5 épocas
    print(f'Época {epoca}: ', losses)
fim = timeit.default_timer()
print('Duração: % ' % (fim - inicio))

historico_loss = []
for i in historico:
  historico_loss.append(i.get('textcat'))

historico_loss = np.array(historico_loss)
historico_loss

import matplotlib.pyplot as plt
plt.plot(historico_loss)
plt.title('Progressão do erro')
plt.xlabel('Lotes')
plt.ylabel('Erro')

modelo.to_disk('modelo')

"""## Etapa 6: Testes com uma frase"""

modelo_carregado = spacy.load('modelo')
modelo_carregado

"""###Teste positivo"""

texto_positivo = base_teste['tweet_text'][21] #Obtendo 22º tweet que representa uma frase positiva
texto_positivo

previsao = modelo_carregado(texto_positivo)
previsao

previsao.cats #Obtendo as probabilidades de cada classe em uma frase a ser testada

#Testando uma frase personalizada
texto_positivo = 'eu gosto muito de você'
texto_positivo = preprocessamento(texto_positivo)
texto_positivo

modelo_carregado(texto_positivo).cats

"""###Teste negativo"""

base_teste['tweet_text'][4000]

texto_negativo = base_teste['tweet_text'][4000]
previsao = modelo_carregado(texto_negativo)
previsao.cats

"""##Etapa 7: Avaliação do modelo

### Avaliação na base de treinamento
"""

#Probabilidades previstas
previsoes_treinamento = []
for texto in base_treinamento['tweet_text']:
  previsao = modelo_carregado(texto)
  previsoes_treinamento.append(previsao.cats)

previsoes

previsoes_final_treinamento = []
for previsao in previsoes:
  if previsao['POSITIVA'] > previsao['NEGATIVA']:
    previsoes_final_treinamento.append(1)
  else:
    previsoes_final_treinamento.append(0)

previsoes_final_treinamento = np.array(previsoes_final_treinamento)

previsoes_final_treinamento

#Probabilidades reais
respostas_reais_treinamento = base_treinamento['sentiment'].values
respostas_reais_treinamento

from sklearn.metrics import confusion_matrix, accuracy_score
accuracy_score(respostas_reais, previsoes_final)

cm = confusion_matrix(respostas_reais, previsoes_final)
cm

sns.heatmap(cm, annot=True)

"""##Avaliação na base de teste"""

previsoes_teste = []
for texto in base_teste['tweet_text']:
  previsao = modelo_carregado(texto)
  previsoes_teste.append(previsao.cats)

previsoes_final_teste = []
for previsao in previsoes_teste:
  if previsao['POSITIVA'] > previsao['NEGATIVA']:
    previsoes_final_teste.append(1)
  else:
    previsoes_final_teste.append(0)
previsoes_final_teste = np.array(previsoes_final_teste)

previsoes_final_teste

respostas_reais_teste = base_teste['sentiment'].values
accuracy_score(respostas_reais_teste, previsoes_final_teste)

cm = confusion_matrix(respostas_reais_teste, previsoes_final_teste)
cm

sns.heatmap(cm, annot=True)